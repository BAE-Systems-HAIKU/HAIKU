{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefaf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before running this notebook, you'll need to download the NSIDC data and CESM1 large ensemble data\n",
    "#using the scripts and instructions in our quickstart guide\n",
    "#the preprocessing script will now map \n",
    "\n",
    "import scripts.preprocessing.preprocess \n",
    "import argparse\n",
    "#There's an issue with 3 files from the NSIDC v4 that will be quickly identified by the script below, \n",
    "#but to save processing time, it's best to delete files: \n",
    "#[seaice_conc_monthly_nh_198407_n07_v04r00.nc, seaice_conc_monthly_nh_198801_f08_v04r00.nc, seaice_conc_monthly_nh_198712_f08_v04r00.nc]\n",
    "#we're not sure why but the values for all points in these regions were set to 0. By removing them from the preprocessing step, \n",
    "#the code will automatically interpolate based on the previous and next time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976913d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#using argparse to remain consistent with command line script in scripts.preprocessing.preprocess.py\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"input_directory\", type=str, default=\"\",\n",
    "        help=\"Directory containing data files\")\n",
    "parser.add_argument(\"reference_gridfile\", type=str,\n",
    "                        help=\"Filepath to grid description textfile\")\n",
    "parser.add_argument(\"output_directory\", type=str, default=\"\",\n",
    "        help=\"Directory to store serialized output\")\n",
    "parser.add_argument(\"--recursive\", \"-r\", action=\"store_true\",\n",
    "        help=\"If specified, recursively process directories \"\n",
    "                         \"within the input directory\")\n",
    "parser.add_argument(\"--pattern\", type=str, default=\"\",\n",
    "        help=\"Optionally only include directories \"\n",
    "                             \"with a pattern match\")\n",
    "#load NASA estimates of NSIDC data\n",
    "args = parser.parse_args([\"/local/simdata/NSIDC/monthly/north_v4/\",\"configs/grids/polar_stereographic_north_grid.txt\",\"/local/preprocessed/\"])\n",
    "scripts.preprocessing.preprocess.main(args)\n",
    "#load SST observational data\n",
    "args = parser.parse_args([\"/local/simdata/NSIDC/monthly/ORAS5/sst/\",\"configs/grids/polar_stereographic_north_grid.txt\",\"/local/preprocessed/\"])\n",
    "scripts.preprocessing.preprocess.main(args)\n",
    "#currently load only one of the CESM1 ensemble members (or averages)\n",
    "preprocess_args = parser.parse_args([\"/local/simdata/CESM1/monthly/002_files/SST/\",\"configs/grids/polar_stereographic_north_grid.txt\",\"/local/preprocessed/\"])\n",
    "scripts.preprocessing.preprocess.main(preprocess_args)\n",
    "\n",
    "#The intent of this step is that we are able to add in additional loading methods for new variables and new datasets\n",
    "#but all downstream analysis is independent of this and koopman models along with prediction analytics can be run \n",
    "#for any combination of 1d or 2d spatial datasets with monthly timesteps (soon any arbitrary time step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f46815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remain consistent between simulation and observational data, we create a mask to make sure \n",
    "#that we skip spatial regions in the simulation where there is no data from observation\n",
    "#you will only need to do this once per analysis regardless of the number of variables or files you wish to process \n",
    "#(assuming your analysis has a consistent spatial grid of interest)\n",
    "import scripts.preprocessing.create_mask\n",
    "\n",
    "#input_filepath should point to a single target .nc file with the grid of interest (use the first NSIDC file from the analysis above)\n",
    "#variable describes the variable of interest for the mask. (use \"cdr_seaice_conc_monthly\" if NSIDC v4 file is your input)\n",
    "#minimum_value and maximum value: any grid points where variable falls outside of this range for the target variable are masked\n",
    "#output_filepath: location to write out the mask file.  You should make sure your configs/config.yml file is updated with this location\n",
    "scripts.preprocessing.create_mask.compute_mask(input_filepath='/local/simdata/NSIDC/monthly/north_v4/seaice_conc_monthly_nh_197903_n07_v04r00.nc',\n",
    "                                              variable=\"cdr_seaice_conc_monthly\",\n",
    "                                              minimum_value=0,\n",
    "                                              maximum_value=100,\n",
    "                                              output_filepath=\"/local/preprocessed/north_nsidc_stereographic_mask.pkl\")\n",
    "#update the config file to point to this mask file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95387e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that you have saved ClimateData objects for all data you wish to model/compare against\n",
    "#You can train a koopman model on the dataset and time window of interest.\n",
    "import scripts.training.train\n",
    "import argparse\n",
    "#You'll need to modify the default configs/configuration file to fit your data\n",
    "#descriptions of all variables can be found there. (most important is to modify the serialized_dat_map)\n",
    "\n",
    "# cli args                                                                                                                         \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"config\", type=str, help=\"Path to configuration file\")\n",
    "#args = parser.parse_args([\"configs/example_config.yml\"])\n",
    "args = parser.parse_args([\"configs/planer_test.yaml\"])\n",
    "scripts.training.train.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a923bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#the above will generate a fully trained koopman model along with some diagnostic plots saved to the output_dir\n",
    "#you can then run the prediction analysis to see what the koopman predictions look like\n",
    "import scripts.prediction.predict\n",
    "import os, argparse\n",
    "#using argparse to remain consistent with command line script in scripts.preprocessing.preprocess.py                                                                                                                      \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"config\", type=str, help=\"Path to configuration file\")\n",
    "parser.add_argument(\"model\", type=str, help=\"Path to serialized model\")\n",
    "parser.add_argument(\"end_date\", type=int, help=\"YYYYMMDD (e.g., 20101201\")\n",
    "parser.add_argument(\"output_directory\", type=str,\n",
    "                    help=\"Where to output plots\")\n",
    "parser.add_argument(\"--upper_mode_bound\", type=int, default=-1,\n",
    "                    help=\"\"\"Prediction will use modes 0 to this upperbound.                                                        \n",
    "                    If not specified, all modes will be used.\"\"\")\n",
    "args = parser.parse_args([\"configs/planer_test.yaml\",\"/local/results_gallery/NSIDC_merged+sst_POLAR_19800101to20091201/koopman_model.pkl\",\"20201201\",\"/local/predictions/\"])\n",
    "\n",
    "# verify                                                                                                                           \n",
    "assert os.path.exists(args.config), \\\n",
    "    f\"{args.config} not found!\"\n",
    "assert os.path.exists(args.model), \\\n",
    "    f\"{args.model} not found!\"\n",
    "os.makedirs(args.output_directory, exist_ok=True)\n",
    "scripts.prediction.predict.main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#robustness analysis can similarly be performed, but works better using the command line utilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
